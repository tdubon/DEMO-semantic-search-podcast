{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Weaviate embedded for question/answering on your vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we use Weaviate Embedded to create a vector store and question/answering from transcribed podcasts. The steps will include uploading your data from a local store, and creating a schema as well as an object store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import json\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An embedded Weaviate instance allows us to have the source data saved and retrieved locally, while having access to the vectorizing modules available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions(\n",
    "        additional_env_vars={\n",
    "        \"ENABLE_MODULES\":\n",
    "        \"text2vec-openai,text2vec-cohere,text2vec-huggingface\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the client information to confirm the modules are loaded.\n",
    "meta_info = client.get_meta()\n",
    "print(json.dumps(meta_info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we setup the schema, an outline requiring the data type, vectorize and class relations. Note that it is essential to have your data cleaned and the categories clearly identified for this step. If using your own vectorizer, \"none\" should be specified for \"vectorizer\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"podcast_ORJj3GQyYa6n\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-10-03T07:59:40-07:00\",\"took\":118745}\n"
     ]
    }
   ],
   "source": [
    "client.schema.delete_all()\n",
    "schema = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"Podcast\",\n",
    "            \"vectorizer\": \"text2vec-cohere\",\n",
    "            \"properties\": [\n",
    "                {\n",
    "                    \"name\": \"title\",\n",
    "                    \"dataType\": [\"text\"]\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"transcript\",\n",
    "                    \"dataType\": [\"text\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "client.schema.create(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we load the locally stored data (in json format) and create a function definition for an add_podcast object. \n",
    "\n",
    "The name of the object represents the highest level classification for your data, indicated below as podcast_object (in dictionary type). Target class represents the next level in the classification of your data. Here we indicate it below as the string \"Podcast\", but note that multiple classes could have been specified, for example, if we had different categories of podcasts, such as English, Spanish, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/tdubon/DEMO-semantic-search-podcast/data/podcast_ds.json\", 'r') as f:\n",
    "    datastore = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_podcasts(batch_size = 1):\n",
    "    no_items_in_batch = 0\n",
    "    for item in datastore:\n",
    "        podcast_object = {\n",
    "            \"title\": item[\"title\"],\n",
    "            \"transcript\": item[\"transcript\"]\n",
    "        }\n",
    "\n",
    "        podcast_uuid = helper.generate_uuid('podcast', item[\"title\"] + item[\"url\"])\n",
    "        client.batch.add_data_object(podcast_object, \"Podcast\", podcast_uuid)\n",
    "        no_items_in_batch += 1\n",
    "\n",
    "        if no_items_in_batch >= batch_size:\n",
    "            results = client.batch.create_objects()\n",
    "\n",
    "            for result in results:\n",
    "                    if result['result'] != {}:\n",
    "                        helper.log(result['result'])\n",
    "\n",
    "            message = str(item[\"title\"]) + ' imported'\n",
    "            helper.log(message)\n",
    "\n",
    "            no_items_in_batch = 0\n",
    "\n",
    "    client.batch.create_objects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'helper' has no attribute 'generate_uuid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m add_podcasts(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m datastore:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     podcast_object \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: item[\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m\"\u001b[39m: item[\u001b[39m\"\u001b[39m\u001b[39mtranscript\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     }\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     podcast_uuid \u001b[39m=\u001b[39m helper\u001b[39m.\u001b[39mgenerate_uuid(\u001b[39m'\u001b[39m\u001b[39mpodcast\u001b[39m\u001b[39m'\u001b[39m, item[\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m item[\u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     client\u001b[39m.\u001b[39mbatch\u001b[39m.\u001b[39madd_data_object(podcast_object, \u001b[39m\"\u001b[39m\u001b[39mPodcast\u001b[39m\u001b[39m\"\u001b[39m, podcast_uuid)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tdubon/Documents/JupyterNotebooks/Embedded_Weaviate.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     no_items_in_batch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'generate_uuid'"
     ]
    }
   ],
   "source": [
    "add_podcasts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you would implement the pipeline for whatever steps you need to take to query your data, such as semantic search, generative search, question/answering. In this example we illustrate question/answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question answering - search wikicity object to answer \"when was London Olympics\"\n",
    "ask = {\n",
    "  \"question\": \"What is this podcast about?\",\n",
    "  \"properties\": [\"podcast_summary\"]\n",
    "}\n",
    "\n",
    "res = (\n",
    "  client.query\n",
    "  .get(\"podcast_object\", [\n",
    "      \"podcast_subject\",\n",
    "      \"_additional {answer {hasAnswer property result} }\"\n",
    "  ])\n",
    "  .with_ask(ask)\n",
    "  .with_limit(1)\n",
    "  .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(res, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
